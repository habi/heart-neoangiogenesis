{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutout a region in the sub-myocard\n",
    "\n",
    "Tim delineated the patch and the myocard.\n",
    "Let's use these two regions and cut out a defined subregion from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import numpy\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn\n",
    "import skimage.filters\n",
    "import dask\n",
    "import dask_image.imread\n",
    "from dask.distributed import Client\n",
    "from numcodecs import Blosc\n",
    "from tqdm.auto import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dask temporary folder\n",
    "# Do this before creating a client: https://stackoverflow.com/a/62804525/323100\n",
    "if 'Linux' in platform.system():\n",
    "    tmp = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "elif 'Darwin' in platform.system():\n",
    "    import tempfile\n",
    "    tmp = tempfile.gettempdir()\n",
    "else:\n",
    "    if 'anaklin' in platform.node():\n",
    "        tmp = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        tmp = os.path.join('D:\\\\')\n",
    "dask.config.set({'temporary_directory': os.path.join(tmp, 'tmp')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start dask client and tell where we can see what it does\n",
    "client = Client()\n",
    "print('You can seee what DASK is doing at \"http://localhost:%s/status\"' % client.scheduler_info()['services']['dashboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings in the notebook\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "plt.rcParams['figure.figsize'] = (8, 4.5)  # Size up figures a bit\n",
    "plt.rcParams['figure.dpi'] = 300  # Increase dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scale bar defaults\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all plots identically\n",
    "lines = 3\n",
    "# And then do something like\n",
    "# plt.subplot(lines, int(numpy.ceil(len(Data) / float(lines))), c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    \"\"\"\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and\n",
    "    http://stackoverflow.com/a/18283905/323100\n",
    "    \"\"\"\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git', '--git-dir', os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse', '--short', '--verify', 'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are we working with?\n",
    "the_current_git_hash = get_git_hash()\n",
    "print('We are working with version %s of the analyis notebook.'\n",
    "      % the_current_git_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output folder\n",
    "# Including the git hash, so we (potentially) have different versions of all the images we generate\n",
    "OutputDir = os.path.join('Output', the_current_git_hash)\n",
    "os.makedirs(OutputDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "if 'anaklin' in platform.node():\n",
    "    FastSSD = True\n",
    "else:\n",
    "    FastSSD = False\n",
    "# to speed things up significantly\n",
    "if 'Linux' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "    else:\n",
    "        BasePath = os.path.join(os.sep, 'home', 'habi', '1272')\n",
    "elif 'Darwin' in platform.system():\n",
    "    BasePath = os.path.join('/Volumes/2TBSSD/')\n",
    "else:\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        if 'anaklin' in platform.node():\n",
    "            BasePath = os.path.join('S:\\\\')\n",
    "        else:\n",
    "            BasePath = os.path.join('D:\\\\', 'Results')\n",
    "Root = os.path.join(BasePath, 'Hearts Melly')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixelsize(logfile):\n",
    "    \"\"\"Get the pixel size from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Image Pixel' in line and 'Scaled' not in line:\n",
    "                pixelsize = float(line.split('=')[1])\n",
    "    return(pixelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three cardinal directions\n",
    "directions = ['Axial', 'Sagittal', 'Coronal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get *all* log files, unsorted but fast\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all folders\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all non-rec logfiles\n",
    "for c, row in Data.iterrows():\n",
    "    if 'rec' not in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'ctan.log' in row.LogFile:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'rectmp.log' in row.LogFile:\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all folders we don't need\n",
    "for c, row in Data.iterrows():\n",
    "    if 'Rat' not in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'Rat4' in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'Rat5' in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'Test' in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate us some meaningful colums\n",
    "Data['Animal'] = [l[len(Root)+1:].split(os.sep)[0] for l in Data['LogFile']]\n",
    "Data['Scan'] = ['.'.join(l[len(Root)+1:].split(os.sep)[1:-1]) for l in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We habe %s scans of %s rats to work with' % (len(Data), len(Data.Animal.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in animals list from Ludovic\n",
    "AnimalTable = pandas.read_excel('Animals.xlsx',\n",
    "                                engine='openpyxl',\n",
    "                                header=None,\n",
    "                                names=['Animal', 'Gender', '', 'Experiment', 'Timepoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in data from animals table\n",
    "for c, rowdata in Data.iterrows():\n",
    "    for d, rowanimals in AnimalTable.iterrows():\n",
    "        if str(rowanimals.Animal) in rowdata.Animal:\n",
    "            Data.at[c, 'Experiment'] = rowanimals.Experiment\n",
    "            Data.at[c, 'Timepoint'] = rowanimals.Timepoint\n",
    "            Data.at[c, 'Gender'] = rowanimals.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we merged the data we can rename the column to a more reusable name\n",
    "Data.columns = Data.columns.str.replace('Animal', 'Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion from Tims visual inspection\n",
    "# R63\n",
    "# R65\n",
    "# R66\n",
    "# R70\n",
    "#exclude = [63, 65, 66, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion from Tims visual inspection for 2214 scans\n",
    "# R67: \"verstrahlt\"\n",
    "# R70: No tachosil\n",
    "#exclude = [63, 65, 66, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop samples which should be excluded\n",
    "# Based on https://stackoverflow.com/a/13851602\n",
    "#for c,row in Data.iterrows():\n",
    "#    for ex in exclude:\n",
    "#        if str(ex) in row.Sample:\n",
    "#            Data.drop(c, inplace=True)\n",
    "#Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"Filter\" to subset that we want\n",
    "# for c,row in Data.iterrows():\n",
    "#     if 'cu_10um' not in row.Scan:\n",
    "#         Data.drop(c, inplace=True)\n",
    "# Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tim delineated both the patch and myocard region\n",
    "# We thus need to duplicate the dataframe for loading them correctly\n",
    "Data = pandas.concat([Data] *2, ignore_index=True)\n",
    "# First sort by animal, then by scan so the VOI colum filling works as intended\n",
    "Data.sort_values(['Sample', 'Scan'], inplace=True)\n",
    "# Fill actual VOI column with alternating values\n",
    "Data['VOI'] = ['myocard', 'patch'] * (len(Data)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head(n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.tail(n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate folder name\n",
    "Data['VOIFolder'] = [os.path.join(os.path.dirname(f),\n",
    "                                  'voi_' + v) for f, v in zip(Data['Folder'], Data['VOI'])]\n",
    "# Load VOI images\n",
    "Data['VOIFiles'] = [sorted(glob.glob(os.path.join(f, '*.png'))) for f in Data['VOIFolder']]\n",
    "Data['Number of VOI slices'] = [len(vs) for vs in Data['VOIFiles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at each VOI folder\n",
    "# And drop those that are empty\n",
    "for c, row in Data.iterrows():\n",
    "    if not len(row['VOIFiles']):\n",
    "        Data.drop(c, inplace=True)\n",
    "Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We habe %s folders of %s samples to look into' % (len(Data), len(Data.Sample.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxelsize from logfiles\n",
    "Data['Voxelsize'] = [get_pixelsize(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all VOI slices into a rechunked DASK array on disk for faster access\n",
    "# Partially based on http://stackoverflow.com/a/39195332/323100\n",
    "# and on /LungMetastasis/HighResolutionScanAnalysis.ipynb\n",
    "Data['OutputNameVOI'] = [os.path.join(os.path.dirname(f),\n",
    "                                      '%s.%s.voi_%s.zarr' % (sample,\n",
    "                                                             scan,\n",
    "                                                             voi)) for f, sample, scan, voi in zip(Data.Folder,\n",
    "                                                                                                   Data.Sample,\n",
    "                                                                                                   Data.Scan,\n",
    "                                                                                                   Data.VOI)]\n",
    "for c, row in tqdm(Data.iterrows(), desc='Reading VOIs', total=len(Data)):\n",
    "    if not os.path.exists(row['OutputNameVOI']):\n",
    "        print('%2s/%s: Reading %s VOI slices from %s and saving to %s' % (c + 1,\n",
    "                                                                          len(Data),\n",
    "                                                                          row['Number of VOI slices'],\n",
    "                                                                          row['VOIFolder'][len(Root)+1:],\n",
    "                                                                          row['OutputNameVOI'][len(Root)+1:]))\n",
    "        VOI = dask_image.imread.imread(os.path.join(row['VOIFolder'], '*.png'))\n",
    "        # Rechunking (to 'auto' size) is slow, but we only need to do it once and\n",
    "        # further reads of the data are much faster.\n",
    "        VOI.rechunk('auto').to_zarr(row['OutputNameVOI'],\n",
    "                                    compressor=Blosc(cname='zstd',\n",
    "                                                     clevel=9,\n",
    "                                                     shuffle=Blosc.BITSHUFFLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reconstructions a zarr arrays\n",
    "Patches = [dask.array.from_zarr(file) for file in Data[Data.VOI == 'patch']['OutputNameVOI']]\n",
    "Myocards = [dask.array.from_zarr(file) for file in Data[Data.VOI == 'myocard']['OutputNameVOI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some dummy data, clear it and append it to dataframe for the MSP VOIs\n",
    "_ = pandas.DataFrame()\n",
    "_ = Data[Data.VOI == 'myocard']\n",
    "_['VOI'].replace(['myocard'], 'myocard_sans_patch', inplace=True)\n",
    "_.loc[:, ('VOIFolder', 'VOIFiles', 'OutputNameVOI', 'Number of VOI slices')] = ''\n",
    "UpDatedData = pandas.concat((Data, _))\n",
    "Data = UpDatedData.copy(deep=True)\n",
    "Data.sort_values(['Sample', 'Scan'], inplace=True)\n",
    "Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Data['VOI'] == 'myocard_sans_patch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 'myocard sans patch' data\n",
    "Data['OutputNameVOI'] = [os.path.join(os.path.dirname(f),\n",
    "                                      '%s.%s.voi_%s.zarr' % (sample,\n",
    "                                                             scan,\n",
    "                                                             voi)) for f, sample, scan, voi in zip(Data.Folder,\n",
    "                                                                                                   Data.Sample,\n",
    "                                                                                                   Data.Scan,\n",
    "                                                                                                   Data.VOI)]\n",
    "# https://stackoverflow.com/a/55437530/323100\n",
    "for c, row in tqdm(enumerate(Data[Data['VOI'] == 'myocard_sans_patch'].iterrows()),\n",
    "                            desc='Calculating MSP VOIs',\n",
    "                            total=len(Data[Data['VOI'] == 'myocard_sans_patch'])):\n",
    "    if not os.path.exists(row[1]['OutputNameVOI']):\n",
    "        print('%2s/%s: Calculating MSP VOI and saving to %s' % (c + 1,\n",
    "                                                                len(Data[ Data['VOI'] == 'myocard_sans_patch']),\n",
    "                                                                row[1]['OutputNameVOI'][len(Root)+1:]))\n",
    "        MSP = dask.array.subtract(Myocards[c], Patches[c])\n",
    "        MSP.rechunk('auto').to_zarr(row[1]['OutputNameVOI'],\n",
    "                                    compressor=Blosc(cname='zstd',\n",
    "                                                     clevel=9,\n",
    "                                                     shuffle=Blosc.BITSHUFFLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MSPs from disk\n",
    "MSP = [dask.array.from_zarr(file) for file in Data[Data.VOI == 'myocard_sans_patch']['OutputNameVOI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 'myocard sans patch' slice\n",
    "whichslice = 444\n",
    "vmax=66\n",
    "for c, sample in enumerate(Data.Sample.unique()):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(Patches[c][whichslice])\n",
    "    plt.imshow(Patches[c][whichslice]!=0, cmap='viridis_r', alpha=0.309)\n",
    "    plt.title('%s: Patch' % sample)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Myocards[c][whichslice])\n",
    "    plt.imshow(Myocards[c][whichslice]!=0, cmap='viridis_r', alpha=0.309)\n",
    "    plt.title('%s: Myocard' % sample)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(MSP[c][whichslice])\n",
    "    plt.imshow(MSP[c][whichslice]!=0, cmap='viridis_r', alpha=0.309)\n",
    "    plt.title('%s: M-P' % sample)   \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load *all* VOIs\n",
    "VOIs = [dask.array.from_zarr(file) for file in Data['OutputNameVOI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big are the datasets?\n",
    "Data['Size'] = [v.shape for v in VOIs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put middle image into dataframe for easier handling\n",
    "Data['Image'] = [v[v.shape[0]//2].compute() for v in VOIs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi(img, verbose=False):\n",
    "    # Extrapolate ROI by thresholding to the data and filling small holes\n",
    "    thresholded_img = skimage.filters.gaussian(img, sigma=0.5) > 0\n",
    "    filled_holes_img = skimage.morphology.remove_small_holes(thresholded_img, 1)\n",
    "    removed_small_stuff_img = skimage.morphology.remove_small_objects(filled_holes_img > 0, 1000)\n",
    "    if verbose:\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Original image')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(142)\n",
    "        plt.imshow(thresholded_img)\n",
    "        plt.title('Thresholded to > 0')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(143)\n",
    "        plt.imshow(filled_holes_img)\n",
    "        plt.title('Filled small holes')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(144)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(numpy.ma.masked_equal(removed_small_stuff_img, 0),\n",
    "                   alpha=0.618,\n",
    "                   cmap='viridis_r')\n",
    "        plt.title('Extrapolated ROI')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return(removed_small_stuff_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it in a loop, so we can use verbose if we want\n",
    "Data['ROI'] = ''\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                   desc='Extrapolate ROI',\n",
    "                   total=len(Data)):\n",
    "    Data.at[c, 'ROI'] = get_roi(row.Image, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(roi, verbose=False):\n",
    "    # Label filled image\n",
    "    labeled_img = skimage.measure.label(roi)\n",
    "    # Extract regionprops of image and put data into pandas\n",
    "    # https://stackoverflow.com/a/66632023/323100\n",
    "    props = skimage.measure.regionprops_table(labeled_img,\n",
    "                                              properties=('label',\n",
    "                                                          'centroid',\n",
    "                                                          'area',\n",
    "                                                          'perimeter',\n",
    "                                                          'orientation'))\n",
    "    table = pandas.DataFrame(props)\n",
    "    table_sorted = table.sort_values(by='area', ascending=False)\n",
    "    # return only the region with the biggest area\n",
    "    properties = table_sorted.iloc[:1].reset_index()\n",
    "    if verbose:\n",
    "        plt.imshow(roi, alpha=0.5)\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(numpy.ma.masked_equal(labeled_img, 0), cmap='viridis', alpha=0.5)\n",
    "        plt.title('Labelled')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it in a loop, so we can use verbose if we want\n",
    "Data['Properties'] = ''\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                            desc='Calculate properties',\n",
    "                            total=len(Data)):\n",
    "    Data.at[c, 'Properties'] = get_properties(row['ROI'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_region(segmentation, verbose=False):\n",
    "    # Get out biggest item from https://stackoverflow.com/a/55110923/323100\n",
    "    labels = skimage.measure.label(segmentation)\n",
    "    assert( labels.max() != 0 ) # assume at least 1 CC\n",
    "    largestCC = labels == numpy.argmax(numpy.bincount(labels.flat)[1:])+1\n",
    "    if verbose:\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(segmentation)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(largestCC)\n",
    "        plt.suptitle('Largest connected component')\n",
    "        plt.show()\n",
    "    return largestCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(filled_img, verbose=False):\n",
    "    # Contouring from https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_regionprops.html\n",
    "    largest_region = get_largest_region(filled_img, verbose=False)\n",
    "    contour = skimage.measure.find_contours(largest_region)\n",
    "    # Even though we look only at the largest region, we still might get out more than one contour\n",
    "    # Let's thus sort the list and just continue with the longest one \n",
    "    (contour).sort(key=len)\n",
    "    cy, cx = contour[-1].T\n",
    "    if verbose:\n",
    "        plt.imshow(filled_img)\n",
    "        plt.plot(cx, cy, lw=1, c='r')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return(cx, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it in a loop, so we can use verbose if we want\n",
    "Data['Contour'] = ''\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                            desc='Extracting contour',\n",
    "                            total=len(Data)):\n",
    "    Data.at[c, 'Contour'] = get_contour(row['ROI'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(img, verbose=False):\n",
    "    props = get_properties(img)\n",
    "    # Drawing from https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_regionprops.html\n",
    "    y0, x0 = props['centroid-0'], props['centroid-1']\n",
    "    if verbose:\n",
    "        plt.imshow(img)\n",
    "        plt.scatter(props['centroid-1'], props['centroid-0'], marker=None, color='r')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return((x0,y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it in a loop, so we can use verbose if we want\n",
    "Data['Centroid'] = ''\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                            desc='Calculating centroid',\n",
    "                            total=len(Data)):\n",
    "    Data.at[c, 'Centroid'] = get_centroid(row['ROI'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_orientation(img, x0, x1, x2, y0, y1, y2, self=False):\n",
    "    if self:\n",
    "        plt.imshow(img)\n",
    "    plt.plot((x0, x1), (y0, y1), '-r', linewidth=1)\n",
    "    plt.plot((x0, x2), (y0, y2), '-r', linewidth=1)\n",
    "    if self:\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation(img, voxelsize, length=5000, verbose=False):\n",
    "    props = get_properties(img)\n",
    "    whichlengthdowewant = length\n",
    "    reallength= whichlengthdowewant / voxelsize # um\n",
    "    # Drawing from https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_regionprops.htm\n",
    "    x0, y0 = get_centroid(img)\n",
    "    x1 = x0 + math.cos(props['orientation']) * reallength\n",
    "    y1 = y0 - math.sin(props['orientation']) * reallength\n",
    "    x2 = x0 - math.sin(props['orientation']) * reallength\n",
    "    y2 = y0 - math.cos(props['orientation']) * reallength\n",
    "    if verbose:\n",
    "        plt.imshow(img)\n",
    "        plt.scatter(props['centroid-1'], props['centroid-0'], marker=None, color='r')\n",
    "        draw_orientation(img, x0, x1, x2, y0, y1, y2)\n",
    "        plt.gca().add_artist(ScaleBar(voxelsize, 'um'))\n",
    "        plt.title('Image with %s um long orientation bars' % length)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return(x0,x1,x2,y0,y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it in a loop, so we can use verbose if we want\n",
    "Data['Orientation'] = ''\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                            desc='Extracting contour',\n",
    "                            total=len(Data)):\n",
    "    Data.at[c, 'Orientation'] = get_orientation(row['ROI'],\n",
    "                                                voxelsize=row['Voxelsize'],\n",
    "                                                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw everything\n",
    "for c,row in tqdm(Data.iterrows(), total=len(Data)):\n",
    "    plt.subplot(lines, int(numpy.ceil(len(Data) / float(lines))), c + 1)\n",
    "    plt.imshow(row.Image)\n",
    "    plt.plot(row.Contour[0], row.Contour[1], lw=1, c='r')\n",
    "    plt.scatter(row.Centroid[0], row.Centroid[1], marker=None, color='w')\n",
    "    draw_orientation(row.ROI,\n",
    "                     row.Orientation[0], row.Orientation[1],\n",
    "                     row.Orientation[2], row.Orientation[3],\n",
    "                     row.Orientation[4], row.Orientation[5])\n",
    "    plt.gca().add_artist(ScaleBar(row.Voxelsize, 'um'))\n",
    "    plt.axis('off')\n",
    "    plt.title('(%s) %s: %s' % (c, row.Sample, row.VOI))\n",
    "    # plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(x1, y1, x2, y2):\n",
    "    '''calculate the middle between two points'''\n",
    "    midpoint = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    return(midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle(x1, y1, x2, y2, verbose=False):\n",
    "    '''calculate the angle between two points'''\n",
    "    # Verbatim copied from https://stackoverflow.com/a/63926786/323100\n",
    "    # Difference in x and y coordinates\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    # Angle between p1 and p2 in radians\n",
    "    theta = math.atan2(dy, dx)\n",
    "    # We will want to `skimage.transform.rotate` in degrees, so return degrees\n",
    "    if verbose:\n",
    "        plt.scatter(x1, y1, label='P1')\n",
    "        plt.scatter(x2, y2, label='P2')\n",
    "        plt.plot((x1, x2), (y1, y2))\n",
    "        plt.scatter(midpoint(x1, y1, x2, y2)[0], midpoint(x1, y1, x1, y2)[1], label='Midpoint')\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    return(math.degrees(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up empty columns\n",
    "Data['Midpoint'] = ''\n",
    "Data['Angle'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate midpoint between the two centroids\n",
    "# Calculate angle between the two centroids\n",
    "for whichone in range(0,len(Data),3):\n",
    "    # Calculate the midpoint and save the (3D) coordinates of it into our dataframe\n",
    "    mp = midpoint(Data['Centroid'][whichone + 1][0], Data['Centroid'][whichone + 1][1],\n",
    "                  Data['Centroid'][whichone + 2][0], Data['Centroid'][whichone + 2][1])\n",
    "    Data.at[whichone + 2, 'Midpoint'] = (Data['Size'][whichone][0]//2,\n",
    "                                         int(round(mp[0].squeeze())),\n",
    "                                         int(round(mp[1].squeeze())))\n",
    "    # Calculate the angle of the line between the centroids. We use this angle alter to rotate the images\n",
    "    ag = angle(Data['Centroid'][whichone + 1][0], Data['Centroid'][whichone + 1][1],\n",
    "                  Data['Centroid'][whichone + 2][0], Data['Centroid'][whichone + 2][1])\n",
    "    Data.at[whichone + 2, 'Angle'] = ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the angle and midpoint calculated above to rotate all scans around the midpoint between the two centroids\n",
    "Data['OutputNameVOIRotated'] = ''\n",
    "for c, row in tqdm(Data.iterrows(), total=len(Data), desc='Rotate images'):\n",
    "    # generate output name, then check if we actually need to do something :)\n",
    "    Data.at[c, 'OutputNameVOIRotated'] = row.OutputNameVOI.replace('.zarr', '.rotated.midpoint%04d.%04d.angle%03d.zarr' % (Data['Midpoint'][c - c % 3 + 2][1],\n",
    "                                                                                                                           Data['Midpoint'][c - c % 3 + 2][2],\n",
    "                                                                                                                           int(round(Data['Angle'][c - c % 3 + 2]))))\n",
    "    if not os.path.exists(Data['OutputNameVOIRotated'][c]):\n",
    "        VOIRotated = numpy.empty_like(VOIs[c].compute())\n",
    "        for d, img in tqdm(enumerate(VOIs[c]),\n",
    "                           total=len(VOIs[c]),\n",
    "                           desc=\"Rotating %s/%s\" % (row.Sample, row.VOI)):\n",
    "            VOIRotated[d]  = skimage.transform.rotate(img.compute(),\n",
    "                                               angle=Data['Angle'][c - c % 3 + 2],\n",
    "                                               center=(Data['Midpoint'][c - c % 3 + 2][1], Data['Midpoint'][c - c % 3 + 2][2]),\n",
    "                                               preserve_range=True)\n",
    "        print('Saving %s/%s (rotated by %s°) to %s' % (row.Sample,\n",
    "                                                       row.VOI,\n",
    "                                                       round(Data['Angle'][c - c % 3 + 2]), Data['OutputNameVOIRotated'][c][len(Root):]))\n",
    "        dask.array.from_array(VOIRotated, chunks='auto').to_zarr(Data['OutputNameVOIRotated'][c],\n",
    "                                                                 overwrite=True,\n",
    "                                                                 compressor=Blosc(cname='zstd',\n",
    "                                                                                  clevel=9,\n",
    "                                                                                  shuffle=Blosc.BITSHUFFLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load *all* rotated VOIs\n",
    "VOIs_rotated = [dask.array.from_zarr(file) for file in Data['OutputNameVOIRotated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rotated middle image (for display below)\n",
    "Data['Image_rotated'] = [v[v.shape[0]//2].compute() for v in VOIs_rotated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display what we calculated above\n",
    "# Push the contrast\n",
    "vmax=128\n",
    "for whichone in range(0, len(Data), 3):\n",
    "    plt.subplot(141)\n",
    "    # Display original data\n",
    "    plt.imshow(Data['Image'][whichone + 1], vmax=vmax)\n",
    "    plt.imshow(Data['Image'][whichone + 2], cmap='viridis', alpha=0.5, vmax=vmax)\n",
    "    # Display the relevant contours\n",
    "    plt.plot(Data['Contour'][whichone + 1][0], Data['Contour'][whichone + 1][1] ,'--',  lw=2,color='w', label='Patch')\n",
    "    plt.plot(Data['Contour'][whichone + 2][0], Data['Contour'][whichone + 2][1], '--', lw=2, color=seaborn.color_palette()[2], label='Myocard')\n",
    "    # Plot the centroids\n",
    "    plt.scatter(Data['Centroid'][whichone + 1][0], Data['Centroid'][whichone + 1][1], color=seaborn.color_palette()[1], s=10, label='Centroid Patch')\n",
    "    plt.scatter(Data['Centroid'][whichone + 2][0], Data['Centroid'][whichone + 2][1], color=seaborn.color_palette()[2], s=10, label='Centroid Myocard')\n",
    "    plt.axis('off')\n",
    "    plt.title('Original data')\n",
    "    plt.legend()\n",
    "    # Display the centerpoint\n",
    "    plt.scatter(Data['Midpoint'][whichone + 2][1], Data['Midpoint'][whichone + 2][2], s=10, label='Center')\n",
    "    plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "    plt.suptitle('Slice %s of %s/%s\\nCenter at %s' % (Data['Size'][whichone][0]//2,\n",
    "                                                      Data['Sample'][whichone],\n",
    "                                                      Data['Scan'][whichone],\n",
    "                                                      Data['Midpoint'][whichone + 2]), y=0.75)\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(Data['Image_rotated'][whichone], vmax=vmax)\n",
    "    plt.scatter(Data['Midpoint'][whichone + 2][1], Data['Midpoint'][whichone + 2][2], s=10, label='Center')    \n",
    "    plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "    plt.axis('off')\n",
    "    plt.title('Myocard + Patch')\n",
    "    \n",
    "    plt.subplot(143)\n",
    "    plt.imshow(Data['Image_rotated'][whichone + 1], vmax=vmax)\n",
    "    plt.scatter(Data['Midpoint'][whichone + 2][1], Data['Midpoint'][whichone + 2][2], s=10, label='Center')\n",
    "    plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "    plt.axis('off')\n",
    "    plt.title('Patch')\n",
    "    \n",
    "    plt.subplot(144)\n",
    "    plt.imshow(Data['Image_rotated'][whichone + 2], vmax=vmax)    \n",
    "    plt.scatter(Data['Midpoint'][whichone + 2][1], Data['Midpoint'][whichone + 2][2], s=10, label='Center')\n",
    "    plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "    plt.axis('off')\n",
    "    plt.title('Myocard - Patch')\n",
    "    # Save the image\n",
    "    outpath = os.path.join(os.path.dirname(Data['Folder'][whichone]), '%s.%s.Rotation.png' % (Data['Sample'][whichone],Data['Scan'][whichone]))\n",
    "    if not os.path.exists(outpath):\n",
    "        plt.savefig(outpath, bbox_inches='tight')\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan', 'Centroid', 'Midpoint', 'VOI', 'Angle']][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puncher(whichone, radius_um, verbose=False):\n",
    "    '''\n",
    "    Punch out a slab around the midpoint.\n",
    "    We will use this for extracting the gray values along the line\n",
    "    '''\n",
    "    print('Working on %s/%s: %s' % (Data['Sample'][whichone],\n",
    "                                        Data['Scan'][whichone],\n",
    "                                        Data['VOI'][whichone]))\n",
    "    radius_px = int(round(radius_um / Data['Voxelsize'][whichone]))        \n",
    "    if verbose:\n",
    "        print('The requested \"radius\" of %s um corresponds to %s px' % (radius_um, radius_px))\n",
    "    midpoint = Data['Midpoint'][whichone - whichone % 3 + 2]\n",
    "    if verbose:\n",
    "        for c,m in enumerate(midpoint):        \n",
    "            print('On axis %s we are cutting out from %s-%s:%s+%s' % (c, m, radius_px, m, radius_px))\n",
    "    # Generate empty image\n",
    "    # We have to use a '.compute()' step to make it work in dask. This is inefficient, but works...\n",
    "    slab = dask.array.zeros_like(VOIs_rotated[whichone]).compute()\n",
    "    # Copy original image values into relevant region\n",
    "    slab[midpoint[0] - radius_px:midpoint[0] + radius_px] = VOIs_rotated[whichone][midpoint[0] - radius_px:midpoint[0] + radius_px].compute()\n",
    "    # Set region outside of slab to zero\n",
    "    if verbose:\n",
    "        print('Setting \":,%s:%s,:\" to False (0)' % (midpoint[1] - radius_px, midpoint[1] + radius_px))\n",
    "        slab[:,:midpoint[2] - radius_px,:] = False\n",
    "        slab[:,midpoint[2] + radius_px:,:] = False\n",
    "#     print(':,:,%s:%s' % (midpoint[2] - radius, midpoint[2] + radius))\n",
    "#     slab[:,:,:midpoint[1] - radius] = 25\n",
    "#     slab[:,:,midpoint[1] + radius:] = 25\n",
    "    if verbose:\n",
    "        # Show what we did there\n",
    "        plt.figure()\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(Data['Image'][whichone])\n",
    "        plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][1], Data['Midpoint'][whichone - whichone % 3 + 2][2])\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "        plt.axis('off')\n",
    "        plt.title('Original')\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(Data['Image_rotated'][whichone], vmax=vmax)\n",
    "        plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][1], Data['Midpoint'][whichone - whichone % 3 + 2][2])\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "        plt.axis('off')\n",
    "        plt.title('Rotated')        \n",
    "        plt.subplot(133)\n",
    "        plt.imshow(slab[slab.shape[0]//2])\n",
    "        plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][1], Data['Midpoint'][whichone - whichone % 3 + 2][2])\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))\n",
    "        plt.axis('off')\n",
    "        plt.title('Slab (middle slice)')        \n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        for ax in range(3):\n",
    "            plt.subplot(1,3,ax+1)\n",
    "            plt.imshow(VOIs_rotated[whichone].max(axis=ax), alpha=0.5, cmap='viridis')\n",
    "            plt.imshow(slab.max(axis=ax), alpha=0.5)\n",
    "            print('%s --> %s' % (whichone, whichone - whichone % 3 + 2))\n",
    "            print(Data['Midpoint'][whichone - whichone % 3 + 2])\n",
    "            if ax == 0:\n",
    "                plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][1], Data['Midpoint'][whichone - whichone % 3 + 2][2], label='Midpoint')\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][2] - radius_px)\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][2] + radius_px)\n",
    "            elif ax == 1:\n",
    "                plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][1], Data['Midpoint'][whichone - whichone % 3 + 2][0], label='Midpoint')\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][0] - radius_px)\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][0] + radius_px)\n",
    "            elif ax == 2:\n",
    "                plt.scatter(Data['Midpoint'][whichone - whichone % 3 + 2][2], Data['Midpoint'][whichone - whichone % 3 + 2][0], label='Midpoint')\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][0] - radius_px)\n",
    "                plt.axhline(Data['Midpoint'][whichone - whichone % 3 + 2][0] + radius_px)        \n",
    "                plt.axvline(Data['Midpoint'][whichone - whichone % 3 + 2][2] - radius_px)\n",
    "                plt.axvline(Data['Midpoint'][whichone - whichone % 3 + 2][2] + radius_px)                \n",
    "            plt.title('Slab MIP Axis %s (overlaid over original)' % ax)\n",
    "            plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))            \n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    return(slab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out a slab from all images\n",
    "radius_um = 250  # um\n",
    "Data['OutputNameSlab'] = ''\n",
    "for c, row in tqdm(Data.iterrows(), total=len(Data), desc='Extracting slab of %s/%s/%s' % (Data['Sample'][c],\n",
    "                                                                                           Data['Scan'][c],\n",
    "                                                                                           Data['VOI'][c])):\n",
    "    # generate output name, then check if we actually need to do something :)\n",
    "    Data.at[c, 'OutputNameSlab'] = row.OutputNameVOI.replace('.zarr', '.rotated.midpoint%04d.%04d.angle%03d.slab.radius%04dum.zarr' % (Data['Midpoint'][c - c % 3 + 2][1],\n",
    "                                                                                                                                       Data['Midpoint'][c - c % 3 + 2][2],\n",
    "                                                                                                                                       int(round(Data['Angle'][c - c % 3 + 2])),\n",
    "                                                                                                                                       radius_um))\n",
    "    if not os.path.exists(Data['OutputNameSlab'][c]):\n",
    "        Slab = puncher(c, radius_um, verbose=True)        \n",
    "        print('Saving a slab of %s/%s to %s' % (row.Sample,\n",
    "                                                row.VOI,\n",
    "                                                Data['OutputNameSlab'][c][len(Root):]))\n",
    "        dask.array.from_array(Slab, chunks='auto').to_zarr(Data['OutputNameSlab'][c],\n",
    "                                                           overwrite=True,\n",
    "                                                           compressor=Blosc(cname='zstd',\n",
    "                                                                            clevel=9,\n",
    "                                                                            shuffle=Blosc.BITSHUFFLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load slabs\n",
    "Slabs = [dask.array.from_zarr(file) for file in Data['OutputNameSlab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichsample = 15\n",
    "slb = Slabs[whichsample]\n",
    "whichslice = Data['Midpoint'][whichsample - whichsample % 3 + 2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(slb.sum(axis=0).sum(axis=1))\n",
    "plt.subplot(131)\n",
    "plt.plot(slb[whichslice].sum(axis=0))\n",
    "plt.subplot(132)\n",
    "plt.imshow(slb.sum(axis=0))\n",
    "plt.subplot(133)\n",
    "plt.plot(slb.sum(axis=0).sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SUMMED gray value  to dataframe\n",
    "Data['GrayValueAlongSlab'] = ''\n",
    "for whichsample in tqdm(range(len(Data)), desc='Calculating gray value along slab'):\n",
    "    Data.at[whichsample, 'GrayValueAlongSlab'] = Slabs[whichsample].sum(axis=0).sum(axis=0).compute()\n",
    "    verbose = False\n",
    "    if verbose:\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(Slabs[whichsample].sum(axis=0))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(Data['GrayValueAlongSlab'][whichsample])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/50011743/323100\n",
    "def rescale_linear(array, new_min, new_max):\n",
    "    \"\"\"Rescale an arrary linearly.\"\"\"\n",
    "    minimum, maximum = numpy.min(array), numpy.max(array)\n",
    "    m = (new_max - new_min) / (maximum - minimum)\n",
    "    b = new_min - m * minimum\n",
    "    return m * array + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize gray value along slab\n",
    "Data['GrayValueAlongSlabNormalized'] = [rescale_linear(gvas, 0, 1) for gvas in Data['GrayValueAlongSlab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm what we did\n",
    "# # Show original image on one side and slab with gray value on the other side\n",
    "# vmax=128\n",
    "# for whichsample in range(len(Data)):\n",
    "#     whichslice = Data['Midpoint'][whichsample - whichsample % 3 + 2][0]\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(VOIs_rotated[whichsample][whichslice], vmax=vmax)\n",
    "#     plt.title('%s/%s: %s' % (Data['Sample'][whichsample],\n",
    "#                              Data['Scan'][whichsample],\n",
    "#                              Data['VOI'][whichsample], ))\n",
    "#     plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))            \n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(Slabs[whichsample][whichslice], vmax=vmax)\n",
    "#     # Some trickery to plot the gray value where we want them\n",
    "#     plt.plot(Data['GrayValueAlongSlabNormalized'][whichsample]*Data['Size'][whichsample][2], alpha=0.618)\n",
    "#     plt.imshow(VOIs_rotated[whichsample][whichslice], vmax=vmax, alpha=0.5, cmap='viridis')\n",
    "#     plt.gca().add_artist(ScaleBar(Data['Voxelsize'][whichone], 'um'))            \n",
    "#     plt.axis('off')\n",
    "#     # Save the image\n",
    "#     outpath = os.path.join(os.path.dirname(Data['Folder'][whichone]), '%s.%s.%s.Slab.png' % (Data['Sample'][whichsample],Data['Scan'][whichsample],Data['VOI'][whichsample]))\n",
    "#     if not os.path.exists(outpath):\n",
    "#         plt.savefig(outpath, bbox_inches='tight')    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_based_on_experiment(exp):\n",
    "    '''Unique color for each experiment value'''\n",
    "    if 'V+P' in exp:\n",
    "        return seaborn.color_palette()[0]\n",
    "    elif 'F' in exp:\n",
    "        return seaborn.color_palette()[1]\n",
    "    elif 'tachosil' in exp:\n",
    "        return seaborn.color_palette()[2]\n",
    "    else :\n",
    "        return seaborn.color_palette()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color (siterrows based on experiment type\n",
    "Data['ColorExperiment'] = [color_based_on_experiment(name) for name in Data.Experiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_based_on_timepoint(tp):\n",
    "    '''Unique color for each timpeoint'''\n",
    "    if tp == 7:\n",
    "        return seaborn.color_palette()[0]\n",
    "    elif tp ==28:\n",
    "        return seaborn.color_palette()[1]\n",
    "    else:\n",
    "        return seaborn.color_palette()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color (scheme), based on experiment time\n",
    "Data['ColorTimepoint'] = [color_based_on_timepoint(tp) for tp in Data.Timepoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, experiment in enumerate(Data.Experiment.unique()):\n",
    "    print(c, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in Data.Experiment.unique():\n",
    "    print(40*'--', exp, 40*'--', exp)\n",
    "    print(Data[Data.Experiment == exp][['Sample', 'Scan', 'VOI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get us some details\n",
    "Data[Data.VOI == 'myocard_sans_patch'].groupby('Experiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Data.VOI == 'myocard'].groupby('Experiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,9)  # Size up figures a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for exp in Data.Experiment.unique():\n",
    "#    for voi in Data.VOI.unique():\n",
    "#        for c,i in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "#            plt.plot(numpy.ma.masked_equal(i.gvas,0).compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort experiment in *this* order\n",
    "DisplayOrderExperiments = sorted(Data.Experiment.unique())\n",
    "ordering = [1, 2, 0, 3]\n",
    "DisplayOrderExperiments[:] = [DisplayOrderExperiments[i] for i in ordering] \n",
    "print('The display order of the experiments is %s' % DisplayOrderExperiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "gs = gridspec.GridSpec(ncols=len(Data.Experiment.unique()),\n",
    "                       nrows=len(Data.VOI.unique()),\n",
    "                       figure=fig)\n",
    "# Iterate through each experiment value\n",
    "for c, exp in enumerate(DisplayOrderExperiments):\n",
    "    # Iterate through every VOI value\n",
    "    for d, voi in enumerate(Data[Data.Experiment == exp].VOI.unique()):\n",
    "        # Generate figure axis\n",
    "        ax=fig.add_subplot(gs[d, c], label=numpy.random.random()*c+d)\n",
    "        for e, row in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "            plt.plot(row.GrayValueAlongSlab,\n",
    "                     color=row.ColorTimepoint,\n",
    "                     label=('%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                             row.Timepoint)))\n",
    "        plt.legend()\n",
    "        if not d:\n",
    "            plt.title(exp)\n",
    "        if not c:\n",
    "            plt.ylabel(voi)\n",
    "        if d ==2:\n",
    "            plt.xlabel('px')\n",
    "plt.savefig(os.path.join(OutputDir, 'GrayValuesAlongSlab.RawData.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is going on with Rat82?\n",
    "Data[Data.Sample == 'Rat82'][['Sample', 'Scan', 'Folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have different *sizes* of images, e.g. the 'gray value along the slab' array has a different length\n",
    "# Outside of the VOI, the values are zero, so we trim to only 'central' part with `numpy.trim_zeros` (https://stackoverflow.com/a/34593911/323100)\n",
    "Data['GrayValueAlongSlab_trimmed_edges'] = [numpy.trim_zeros(gvas) for gvas in Data['GrayValueAlongSlab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trimmed data\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "gs = gridspec.GridSpec(ncols=len(Data.Experiment.unique()),\n",
    "                       nrows=len(Data.VOI.unique()),\n",
    "                       figure=fig)\n",
    "# Iterate through each experiment value\n",
    "for c, exp in enumerate(DisplayOrderExperiments):\n",
    "    # Iterate through every VOI value\n",
    "    for d, voi in enumerate(Data[Data.Experiment == exp].VOI.unique()):\n",
    "        # Generate figure axis\n",
    "        ax=fig.add_subplot(gs[d, c], label=numpy.random.random()*c+d)\n",
    "        for e, row in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "            plt.plot(row.GrayValueAlongSlab_trimmed_edges,\n",
    "                     color=row.ColorTimepoint,\n",
    "                     label=('%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                             row.Timepoint)))\n",
    "        plt.legend()\n",
    "        if not d:\n",
    "            plt.title(exp)\n",
    "        if not c:\n",
    "            plt.ylabel(voi)\n",
    "        if d ==2:\n",
    "            plt.xlabel('px')\n",
    "        plt.xlim([0,1111])\n",
    "plt.savefig(os.path.join(OutputDir, 'GrayValuesAlongSlab.TrimmedEdges.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do *not* actually just trim the msp peak (from not perfect delieation from Tim) at the start,\n",
    "# but get rid of it by simply overwriting it with '0', so we can still plot everything with the same length below\n",
    "for d, row in Data[Data.VOI=='myocard_sans_patch'].iterrows(): # only for msp\n",
    "    row['GrayValueAlongSlab_trimmed_edges'][:125] = 0  # '125' is an empirically found value to discard everything from the peak but not more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trimmed data without msp peak at the start\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "gs = gridspec.GridSpec(ncols=len(Data.Experiment.unique()),\n",
    "                       nrows=len(Data.VOI.unique()),\n",
    "                       figure=fig)\n",
    "# Iterate through each experiment value\n",
    "for c, exp in enumerate(DisplayOrderExperiments):\n",
    "    # Iterate through every VOI value\n",
    "    for d, voi in enumerate(Data[Data.Experiment == exp].VOI.unique()):\n",
    "        # Generate figure axis\n",
    "        ax=fig.add_subplot(gs[d, c], label=numpy.random.random()*c+d)\n",
    "        for e, row in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "            plt.plot(row.GrayValueAlongSlab_trimmed_edges,\n",
    "                     color=row.ColorTimepoint,\n",
    "                     label=('%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                             row.Timepoint)))\n",
    "        plt.legend()\n",
    "        if not d:\n",
    "            plt.title(exp)\n",
    "        if not c:\n",
    "            plt.ylabel(voi)\n",
    "        if d ==2:\n",
    "            plt.xlabel('px')\n",
    "plt.savefig(os.path.join(OutputDir, 'GrayValuesAlongSlab.msp_peak_trim.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the discussion with Ludovic on 01.12.22 it dawned on me that we *have* to set the origin of all our plots on the heart surface\n",
    "# and not on the surface of the sample (which includes the patch)\n",
    "# Since we're masking out the peak from the subtraction above, we can just `numpy.trim_zeros` the *start* of *all* the gray values.\n",
    "# This does only something for the the gray values of the msp data and thus we can do a little happy dance :)\n",
    "Data['GrayValueAlongSlab_fully_trimmed'] = [numpy.trim_zeros(gvas, trim='f') for gvas in Data['GrayValueAlongSlab_trimmed_edges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate us an mm x-axis scale\n",
    "# We want to plot in mm, so divide by 1000\n",
    "# Since we discareded the msp peak above, we can front-trim all the gray values again.\n",
    "Data['XAxisScale_Pixelsize'] = [[row.Voxelsize * i / 1000 for i in list(range(len(gvas)))] for vs, gvas in zip(Data.Voxelsize, Data.GrayValueAlongSlab_fully_trimmed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save maximum gray value along slab into dataframe, to use for plotting\n",
    "Data['GrayValueAlongSlabMax'] = ''\n",
    "for d, gvas in enumerate(Data['GrayValueAlongSlab_trimmed_edges']):\n",
    "    Data.at[d, 'GrayValueAlongSlabMax'] = gvas.max()\n",
    "# Print the common maximal gray value, rounded up\n",
    "for d, voi in enumerate(Data.VOI.unique()):\n",
    "    print(voi, int(numpy.ceil(round(Data[Data.VOI==voi]['GrayValueAlongSlabMax'].max() / 1e5, 2)) * 1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save maximum 'depth' value into dataframe\n",
    "Data['SlabLength'] = ''\n",
    "for d, mm in enumerate(Data['XAxisScale_Pixelsize']):\n",
    "    Data.at[d, 'SlabLength'] = max(mm)\n",
    "# Print the common maximal value\n",
    "for d, voi in enumerate(Data.VOI.unique()):\n",
    "    print(voi, round(Data[Data.VOI==voi]['SlabLength'].max()) + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trimmed data without msp peak at the start, with the x-axis in SI values\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "gs = gridspec.GridSpec(ncols=len(Data.Experiment.unique()),\n",
    "                       nrows=len(Data.VOI.unique()),\n",
    "                       figure=fig)\n",
    "# Iterate through each experiment value\n",
    "for c, exp in enumerate(DisplayOrderExperiments):\n",
    "    # Iterate through every VOI value\n",
    "    for d, voi in enumerate(Data[Data.Experiment == exp].VOI.unique()):\n",
    "        # Generate figure axis\n",
    "        ax=fig.add_subplot(gs[d, c], label=numpy.random.random()*c+d)\n",
    "        for e, row in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "            # Patch needs to be flipped, Myocard and MSP not\n",
    "            if voi == 'patch':  # Flip the values and plot them the 'wrong way', so 0 is to the right\n",
    "                plt.plot(row.XAxisScale_Pixelsize, numpy.flip(row.GrayValueAlongSlab_fully_trimmed),\n",
    "                         color=row.ColorTimepoint,\n",
    "                         label=('%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                                 row.Timepoint)))\n",
    "                plt.xlim([2, 0])\n",
    "                plt.ylim(ymax=3e5)\n",
    "            else:\n",
    "                plt.plot(row.XAxisScale_Pixelsize, row.GrayValueAlongSlab_fully_trimmed,\n",
    "                     color=row.ColorTimepoint,\n",
    "                     label=('%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                             row.Timepoint)))\n",
    "                if voi == 'myocard':\n",
    "                    # Adjust the xlim to the maximum value\n",
    "                    plt.xlim(right=numpy.ceil(Data['SlabLength'].max()))\n",
    "                    # Adjust the ylim to the maximum value rounded up to the next 1e5\n",
    "                    plt.ylim(top=numpy.ceil(round(Data[Data.VOI==voi]['GrayValueAlongSlabMax'].max() / 1e5, 2)) * 1e5)\n",
    "                else:\n",
    "                    # Adjust to show only X mm depth\n",
    "                    plt.xlim([0, 2])\n",
    "                    plt.ylim(ymax=3e5)\n",
    "        # Legends and labeling\n",
    "        plt.legend()\n",
    "        if not d:  # 'not d' -> Top row. Only this row gets a title\n",
    "            plt.title(exp)\n",
    "        if not c:  # 'not c' --> First colum. Only this columng gets a y-label\n",
    "            plt.ylabel(voi)\n",
    "        if d == 2:  # Only bottom row gets an x-label\n",
    "            plt.xlabel('mm')    \n",
    "plt.savefig(os.path.join(OutputDir, 'GrayValuesAlongSlab.Origin-At-Heartsurface.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Timepoint.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trimmed data without msp peak at the start, with the x-axis in SI values\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "gs = gridspec.GridSpec(ncols=len(Data.Experiment.unique()),\n",
    "                       nrows=len(Data.VOI.unique()),\n",
    "                       figure=fig)\n",
    "# Iterate through each experiment value\n",
    "for c, exp in enumerate(DisplayOrderExperiments):\n",
    "    # Iterate through every VOI value\n",
    "    for d, voi in enumerate(Data[Data.Experiment == exp].VOI.unique()):\n",
    "        # Generate figure axis\n",
    "        ax=fig.add_subplot(gs[d, c], label=numpy.random.random()*c+d)\n",
    "        for e, row in Data[(Data.Experiment == exp) & (Data.VOI==voi)].iterrows():\n",
    "            # Patch needs to be flipped, Myocard and MSP not\n",
    "            if voi == 'patch':  # Flip the values and plot them the 'wrong way', so 0 is to the right\n",
    "                plt.plot(row.XAxisScale_Pixelsize, numpy.flip(row.GrayValueAlongSlab_fully_trimmed),\n",
    "#                          color=row.ColorTimepoint,\n",
    "                         label=('%s/%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                                    row.Scan.replace('.rec',''),\n",
    "                                                    row.Timepoint)))\n",
    "                plt.xlim([2, 0])\n",
    "                plt.ylim(ymax=2.75e5)\n",
    "            else:\n",
    "                plt.plot(row.XAxisScale_Pixelsize, row.GrayValueAlongSlab_fully_trimmed,\n",
    "#                      color=row.ColorTimepoint,\n",
    "                     label=('%s/%s (d %0.f)' % (row.Sample.replace('Rat',''),\n",
    "                                                row.Scan.replace('.rec',''),\n",
    "                                                row.Timepoint)))\n",
    "                if voi == 'myocard':\n",
    "                    # Adjust the xlim to the maximum value\n",
    "                    plt.xlim(right=numpy.ceil(Data['SlabLength'].max()))\n",
    "                    # Adjust the ylim to the maximum value rounded up to the next 1e5\n",
    "                    plt.ylim(top=numpy.ceil(round(Data[Data.VOI==voi]['GrayValueAlongSlabMax'].max() / 1e5, 2)) * 1e5)\n",
    "                else:\n",
    "                    # Adjust to show only X mm depth\n",
    "                    plt.xlim([0, 2])\n",
    "                    plt.ylim(ymax=2.75e5)\n",
    "        # Legends and labeling\n",
    "        plt.legend()\n",
    "        if not d:  # 'not d' -> Top row. Only this row gets a title\n",
    "            plt.title(exp)\n",
    "        if not c:  # 'not c' --> First colum. Only this columng gets a y-label\n",
    "            plt.ylabel(voi)\n",
    "        if d == 2:  # Only bottom row gets an x-label\n",
    "            plt.xlabel('mm')    \n",
    "plt.savefig(os.path.join(OutputDir, 'GrayValuesAlongSlab.Origin-At-Heartsurface.Colorized.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZE THE GRAY VALUES TO THE *FULL* GRAY VALUES OF THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZE TO FULL DATA OR NORMALIZE TO ONLY DATA IN VIRTUAL PUNCH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myocards[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute *all* histograms we might need later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkh = [dask.array.histogram(m, bins=2**8, range=[0, 255]) for m in Myocards]\n",
    "mkh = [h.compute() for h,b in mkh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = [dask.array.histogram(m, bins=2**8, range=[0, 255]) for m in Patches]\n",
    "ph = [h.compute() for h,b in ph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all (original, uncropped) reconstructions into ephemereal DASK arrays\n",
    "Reconstructions = [None] * len(Data)\n",
    "for c, row in tqdm(Data.iterrows(), desc='Load reconstructions', total=len(Data)):\n",
    "    Reconstructions[c] = dask_image.imread.imread(os.path.join(row['Folder'], '*rec*.png')).rechunk(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = [dask.array.histogram(r, bins=2**8, range=[0, 255]) for r in Reconstructions]\n",
    "rh = [h.compute() for h,b in rh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "for i in rh:\n",
    "    plt.semilogy(i)\n",
    "plt.title('Reconstructions histograms')\n",
    "plt.subplot(132)\n",
    "for i in mkh:\n",
    "    plt.semilogy(i)\n",
    "plt.title('Myocard histograms')\n",
    "plt.subplot(133)\n",
    "for i in ph:\n",
    "    plt.semilogy(i)\n",
    "plt.title('Patch histograms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mkh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data[Data.VOI == 'myocard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Data.VOI == 'myocard'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,row in Data[Data.VOI == 'myocard'].iterrows():\n",
    "    print(c, row.Sample, row.Scan)\n",
    "    plt.semilogy(mkh[c], label='%s/%s' % (row.Sample, row.Scan))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data[Data.VOI == 'myocard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
